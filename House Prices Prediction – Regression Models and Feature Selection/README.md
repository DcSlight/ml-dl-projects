# House Prices Prediction â€“ Regression Models and Feature Selection

This project applies machine learning regression techniques to predict house prices using the Kaggle dataset "House Prices: Advanced Regression Techniques."

## Overview

- **Dataset:** Ames, Iowa house prices dataset from Kaggle
- **Task:** Predict numeric sale prices
- **Evaluation Metric:** Root Mean Squared Error (RMSE)
- **Platform:** All experiments conducted in a Kaggle Notebook

## Models Used

- K-Nearest Neighbors Regression (KNN)
- Locally Weighted Linear Regression (LWLR)
- Decision Trees

_One or more models were selected and compared._

## Ensemble Methods

Applied ensemble learning techniques:

- Bagging
- Boosting
- Random Forests

_Ensemble methods were compared and their impact on performance analyzed._

## Dimensionality Reduction

- Used Principal Component Analysis (PCA) to reduce feature dimensionality.

## Workflow

1. **Model Training**

   - Trained selected regression models and ensembles.
   - Applied PCA to explore dimensionality reduction.

2. **Hyperparameter Tuning**

   - Tested different parameter configurations.
   - Evaluated performance with cross-validation.

3. **Evaluation**

   - Compared RMSE across models and ensembles.
   - Visualized training and validation loss over epochs.
   - Analyzed differences between evaluation metrics.

4. **Submission**

   - Generated predictions and submitted results to the Kaggle leaderboard.
   - Documented submission scores and leaderboard ranking.

5. **Analysis**
   - Discussed model strengths, limitations, and insights.
